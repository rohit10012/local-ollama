# local-ollama
This is a simple code to run any llm locally
